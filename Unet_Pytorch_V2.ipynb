{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306a8a37-87f4-4706-9b55-adc4355dc2ff",
   "metadata": {},
   "source": [
    "#### `Import library`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bee323e-f9b4-43a0-8fe1-e1f3c705b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from patchify import patchify\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from unet import UNet\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908fc2d4-4c48-448f-b1ca-015838e8cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "patch_size = 256\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a898f69b-17ee-4431-980e-d3dd9b2c6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color to Class Mapping\n",
    "def hex_to_rgb(hex_code):\n",
    "    hex_code = hex_code.lstrip('#')\n",
    "    return np.array(tuple(int(hex_code[i:i+2], 16) for i in (0, 2, 4)))\n",
    "\n",
    "COLOR_MAP = {\n",
    "    0: hex_to_rgb('#3C1098'),  # Building\n",
    "    1: hex_to_rgb('#8429F6'),  # Land\n",
    "    2: hex_to_rgb('#6EC1E4'),  # Road\n",
    "    3: hex_to_rgb('FEDD3A'),   # Vegetation\n",
    "    4: hex_to_rgb('E2A929'),   # Water\n",
    "    5: hex_to_rgb('#9B9B9B')   # Unlabeled\n",
    "}\n",
    "\n",
    "def rgb_to_2D_label(label):\n",
    "    label_seg = np.zeros(label.shape[:2], dtype=np.uint8)\n",
    "    for k, v in COLOR_MAP.items():\n",
    "        matches = np.all(label == v, axis=-1)\n",
    "        label_seg[matches] = k\n",
    "    return label_seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed0c44f-ebcd-42bd-9769-9ab2ff92d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset class using CSV file\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.image_patches = []\n",
    "        self.mask_patches = []\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_path = row['Image']\n",
    "            mask_path = row['Mask']\n",
    "\n",
    "            # Load and crop image\n",
    "            img = cv2.imread(img_path)\n",
    "            h, w = img.shape[:2]\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.crop((0, 0, (w // patch_size) * patch_size, (h // patch_size) * patch_size))\n",
    "            img = np.array(img)\n",
    "            img_patches = patchify(img, (patch_size, patch_size, 3), step=patch_size)\n",
    "\n",
    "            # Load and crop mask\n",
    "            mask = cv2.imread(mask_path)\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "            mask = Image.fromarray(mask)\n",
    "            mask = mask.crop((0, 0, (w // patch_size) * patch_size, (h // patch_size) * patch_size))\n",
    "            mask = np.array(mask)\n",
    "            mask_patches = patchify(mask, (patch_size, patch_size, 3), step=patch_size)\n",
    "\n",
    "            for i in range(img_patches.shape[0]):\n",
    "                for j in range(img_patches.shape[1]):\n",
    "                    img_patch = img_patches[i, j, 0]\n",
    "                    img_patch = scaler.fit_transform(img_patch.reshape(-1, 3)).reshape(img_patch.shape)\n",
    "                    mask_patch = rgb_to_2D_label(mask_patches[i, j, 0])\n",
    "                    self.image_patches.append(img_patch)\n",
    "                    self.mask_patches.append(mask_patch)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.image_patches[idx], dtype=torch.float32).permute(2, 0, 1)\n",
    "        mask = torch.tensor(self.mask_patches[idx], dtype=torch.long)\n",
    "        return image, mask\n",
    "\n",
    "# Detect device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179f7e2b-7eaf-4917-b7db-73abbf7f977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = SegmentationDataset('train.csv')\n",
    "test_dataset = SegmentationDataset('test.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Number of classes\n",
    "all_masks = np.concatenate([mask.numpy().flatten() for _, mask in train_dataset])\n",
    "n_classes = len(np.unique(all_masks))\n",
    "\n",
    "# Define model, loss, optimizer\n",
    "model = UNet(n_classes=n_classes, in_channels=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48c6d3-341e-465c-b3ad-9710b104a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.7364, Test Loss: 1.3885\n",
      "Epoch 2, Train Loss: 1.5163, Test Loss: 1.3885\n",
      "Epoch 3, Train Loss: 1.5160, Test Loss: 1.3885\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Evaluation on test data\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'unet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a7c24-5971-4915-b15b-9f98b886fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Train vs Test Loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(test_losses, label='Test Loss', color='orange')\n",
    "plt.title(\"Train vs Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8e2a4-1cc6-45d9-b9a0-0821d6cf33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load helper functions and color map ---\n",
    "def hex_to_rgb(hex_code):\n",
    "    hex_code = hex_code.lstrip('#')\n",
    "    return np.array(tuple(int(hex_code[i:i+2], 16) for i in (0, 2, 4)))\n",
    "\n",
    "COLOR_MAP = {\n",
    "    0: hex_to_rgb('#3C1098'),  # Building\n",
    "    1: hex_to_rgb('#8429F6'),  # Land\n",
    "    2: hex_to_rgb('#6EC1E4'),  # Road\n",
    "    3: hex_to_rgb('FEDD3A'),   # Vegetation\n",
    "    4: hex_to_rgb('E2A929'),   # Water\n",
    "    5: hex_to_rgb('#9B9B9B')   # Unlabeled\n",
    "}\n",
    "\n",
    "def rgb_to_2D_label(label):\n",
    "    label_seg = np.zeros(label.shape[:2], dtype=np.uint8)\n",
    "    for k, v in COLOR_MAP.items():\n",
    "        matches = np.all(label == v, axis=-1)\n",
    "        label_seg[matches] = k\n",
    "    return label_seg\n",
    "\n",
    "def label_to_rgb(label_2d):\n",
    "    rgb_img = np.zeros((label_2d.shape[0], label_2d.shape[1], 3), dtype=np.uint8)\n",
    "    for k, v in COLOR_MAP.items():\n",
    "        rgb_img[label_2d == k] = v\n",
    "    return rgb_img\n",
    "\n",
    "# --- Define device ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Load model ---\n",
    "model = UNet(n_classes=6, in_channels=3).to(device)  # Make sure UNet class is defined\n",
    "model.load_state_dict(torch.load('unet_model.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# --- Load first image and mask from val.csv ---\n",
    "val_df = pd.read_csv('val.csv')\n",
    "image_path = val_df.iloc[5]['Image']\n",
    "mask_path = val_df.iloc[5]['Mask']\n",
    "\n",
    "# --- Load image ---\n",
    "patch_size = 256\n",
    "img = cv2.imread(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_crop = Image.fromarray(img_rgb).crop((0, 0, (img.shape[1] // patch_size) * patch_size, (img.shape[0] // patch_size) * patch_size))\n",
    "img_np = np.array(img_crop)\n",
    "\n",
    "# Normalize\n",
    "img_norm = img_np / 255.0\n",
    "img_tensor = torch.tensor(img_norm, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "# --- Inference ---\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)\n",
    "    predicted_mask = torch.argmax(output.squeeze(), dim=0).cpu().numpy()\n",
    "\n",
    "# --- Load ground truth mask ---\n",
    "gt_mask = cv2.imread(mask_path)\n",
    "gt_mask = cv2.cvtColor(gt_mask, cv2.COLOR_BGR2RGB)\n",
    "gt_crop = Image.fromarray(gt_mask).crop((0, 0, (gt_mask.shape[1] // patch_size) * patch_size, (gt_mask.shape[0] // patch_size) * patch_size))\n",
    "gt_mask_np = np.array(gt_crop)\n",
    "gt_label = rgb_to_2D_label(gt_mask_np)\n",
    "\n",
    "# --- Convert masks to RGB for plotting ---\n",
    "pred_rgb = label_to_rgb(predicted_mask)\n",
    "gt_rgb = label_to_rgb(gt_label)\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(pred_rgb)\n",
    "plt.title(\"Predicted Segmentation\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(gt_rgb)\n",
    "plt.title(\"Ground Truth Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25d066-c0c4-4033-b0db-af8e29859b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
